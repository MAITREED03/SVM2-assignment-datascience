{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7ec275-22e2-47b3-afec-1c91adfc33aa",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "\n",
    "\n",
    "In machine learning algorithms, especially in the context of Support Vector Machines (SVMs) and other kernelized models, the relationship between polynomial functions and kernel functions lies in the way they are used to transform input data into a higher-dimensional space.\n",
    "\n",
    "Polynomial Functions:\n",
    "\n",
    "A polynomial function is a mathematical function consisting of one or more terms, each with a variable raised to a non-negative integer exponent. For example, f(x)=ax**2+bx+c is a second-degree polynomial.\n",
    "In the context of machine learning, polynomial functions are often used to create feature mappings that transform input data from a lower-dimensional space to a higher-dimensional space. This transformation can make the data more amenable to linear separation.\n",
    "Kernel Functions:\n",
    "\n",
    "Kernel functions, in the context of kernelized machine learning algorithms like SVMs, play a crucial role in implicitly mapping data into a higher-dimensional space without explicitly computing the transformation.\n",
    "The polynomial kernel is a specific type of kernel function that computes the dot product of the transformed feature vectors in a higher-dimensional space without explicitly computing the transformation. The polynomial kernel is defined as K(x,y)=(x⋅y+c) **d\n",
    "where d is the degree of the polynomial and c is a constant term.\n",
    "The polynomial kernel essentially captures the inner product of the transformed feature vectors in a higher-dimensional space, making it possible to perform computations in the higher-dimensional space without explicitly transforming the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fdac27-8255-4385-b5cb-68fffdeb8485",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "\n",
    "simple example of how to implement a Support Vector Machine (SVM) with a polynomial kernel using Scikit-learn in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d106684-e790-4cf3-8f29-c70b09eb555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM with polynomial kernel: 0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features for simplicity\n",
    "y = iris.target\n",
    "\n",
    "# Create a SVM model with a polynomial kernel\n",
    "model = svm.SVC(kernel='poly')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X, y)\n",
    "print(\"Accuracy of SVM with polynomial kernel:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422664c-f5de-4cd6-a27e-40004f33bc67",
   "metadata": {},
   "source": [
    "•\tWe first import the necessary libraries and load the iris dataset.\n",
    "•\tWe then create an SVM model with a polynomial kernel using svm.SVC(kernel='poly').\n",
    "•\tThe model is trained on the data using the fit() method.\n",
    "•\tWe make predictions on the same data using the predict() method.\n",
    "•\tFinally, we evaluate the model’s performance by calculating the accuracy of the predictions1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb8075-4729-4d22-8cf0-fe9904a76819",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "In Support Vector Regression (SVR), epsilon (ε) is a hyperparameter that defines the width of the epsilon-tube, also known as the epsilon-insensitive zone. The epsilon-insensitive zone is the range within which errors are considered acceptable and do not contribute to the loss function.\n",
    "\n",
    "The impact of increasing the value of epsilon on the number of support vectors in SVR depends on the nature of the data and the chosen epsilon value. Here are two scenarios:\n",
    "\n",
    "Large Epsilon (ε):\n",
    "\n",
    "When epsilon is set to a large value, the epsilon-insensitive zone becomes wider, allowing for larger errors to be considered acceptable. This means that data points within this wider zone are not treated as errors, and they do not contribute significantly to the loss function.\n",
    "In this case, the SVR model may have fewer support vectors because it can tolerate larger errors, and fewer data points are needed to define the regression function within the acceptable error range.\n",
    "Small Epsilon (ε):\n",
    "\n",
    "Conversely, when epsilon is set to a small value, the epsilon-insensitive zone becomes narrower, making the SVR model less tolerant to errors. Only data points within this smaller zone are considered acceptable, and any points outside this zone contribute to the loss.\n",
    "With a smaller epsilon, the SVR model may require more support vectors to accurately fit the data within the constrained error range. This is because the model needs to consider a greater number of data points to satisfy the stricter epsilon criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff3458-eedc-4290-8d70-1b86c1d92880",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "\n",
    "Support Vector Regression (SVR) is a type of regression algorithm that uses support vector machines to perform regression tasks. The performance of SVR can be significantly influenced by several key parameters: the choice of kernel function, C parameter, epsilon parameter (ε), and gamma parameter (γ). Let's discuss each parameter and its impact:\n",
    "\n",
    "Kernel Function:\n",
    "\n",
    "The kernel function determines the mapping of input features into a higher-dimensional space. Common kernel functions include linear, polynomial, and radial basis function (RBF or Gaussian).\n",
    "Example: Choose a linear kernel if the relationship between input features and the target variable is expected to be approximately linear. Use RBF kernel for non-linear relationships.\n",
    "C Parameter:\n",
    "\n",
    "The C parameter controls the trade-off between achieving a low training error and a low testing error. A smaller C allows a smoother decision surface with a larger margin but may tolerate training errors. A larger C penalizes training errors more heavily, potentially leading to a more complex model with a smaller margin.\n",
    "Example: Increase C if the model is underfitting and the training error is too high. Decrease C if the model is overfitting, and you want a smoother decision surface.\n",
    "Epsilon Parameter (ε):\n",
    "\n",
    "The epsilon parameter defines the size of the epsilon-insensitive tube, which is the range within which errors are not penalized. It controls the acceptable margin of error in the predictions.\n",
    "Example: If you expect some noise in the target variable, you might increase ε to allow for a larger margin of error.\n",
    "Gamma Parameter (γ):\n",
    "\n",
    "The gamma parameter influences the shape of the decision boundary and the reach of each training example. A smaller γ results in a larger reach and a smoother decision boundary, while a larger γ leads to a more complex, tightly fitted decision boundary.\n",
    "Example: Increase γ when the model is underfitting, and you want a more complex decision boundary. Decrease γ if the model is overfitting, and you want a smoother decision boundary.\n",
    "Choosing appropriate values for these parameters often involves experimentation and cross-validation. Here are general guidelines:\n",
    "\n",
    "If the model is too complex and overfitting, consider decreasing C, γ, and increasing ε.\n",
    "If the model is too simple and underfitting, consider increasing C, \n",
    "γ, and possibly decreasing ε.\n",
    "For the kernel choice, start with a linear kernel and switch to a non-linear kernel (e.g., RBF) if needed for capturing complex relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad9d517-0cca-4f55-be25-f336538c82d2",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1c46e7-45b2-4594-8b01-b58fe7ef65ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Best Hyperparameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Train the tuned classifier on the entire dataset\u001b[39;00m\n\u001b[1;32m     46\u001b[0m best_svc \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m---> 47\u001b[0m best_svc\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_scaled\u001b[49m, y)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Save the trained classifier to a file for future use\u001b[39;00m\n\u001b[1;32m     50\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(best_svc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_svc_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib  # To save the trained model\n",
    "\n",
    "# Load the dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (standardization in this case)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy as the metric\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report for additional metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Tune the hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 0.01, 0.001, 0.0001], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "best_svc = grid_search.best_estimator_\n",
    "best_svc.fit(X_scaled, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(best_svc, 'trained_svc_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e6f63-d3fb-46c5-9f21-d38cbb5e65cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
